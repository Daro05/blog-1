@conference{signaltrain,
  title = {<a href="https://hedges.belmont.edu/~shawley/signaltrain_paper_aes.pdf">Profiling Audio Compressors with Deep Neural Networks</a>},
  author = {Hawley, Scott H. and Colburn, Benjamin and Mimilakis, Stylianos Ioannis},
  booktitle = {Audio Engineering Society Convention 147},
  month = {Oct},
  year = {2019},
  url = {http://www.aes.org/e-lib/browse.cfm?elib=20595}
}


@article{billy_signaltrain2,
  title={<a href="https://arxiv.org/abs/2006.05584">Exploring Quality and Generalizability in Parameterized Neural Audio Effects</a>},
  author={William Mitchell and Scott H. Hawley},
  journal={ArXiv},
  year={2020},
  volume={abs/2006.05584},
  url = {https://arxiv.org/abs/2006.05584}
}


@incollection{costa_features_categories,
title = {<a href="https://www.researchgate.net/publication/339271541_On_Features_and_Categories_CDT-20">On Features and Categories (CDT-20)</a>},
author = {da F. Costa, Luciano},
year = {2020},
month = {02},
pages = {},
booktitle = {Costa's Didactic Texts},
doi = {10.13140/RG.2.2.25069.54249},
url = "https://www.researchgate.net/publication/339271541_On_Features_and_Categories_CDT-20",
}


@article{fukushima,
  title = {<a href="https://www.rctn.org/bruno/public/papers/Fukushima1980.pdf">{N}eocognitron: {A} Self-Organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position</a>},
  added-at = {2008-03-11T14:52:34.000+0100},
  author = {Fukushima, Kunihiko},
  biburl = {https://www.bibsonomy.org/bibtex/29ecd878c4827c46dab6b9622cfa00072/idsia},
  citeulike-article-id = {2376719},
  interhash = {303975e6400e477e91c91e7dc2c47544},
  intrahash = {9ecd878c4827c46dab6b9622cfa00072},
  journal = {Biological Cybernetics},
  keywords = {nn},
  pages = {193--202},
  priority = {2},
  timestamp = {2008-03-11T15:04:22.000+0100},
  url = {https://www.rctn.org/bruno/public/papers/Fukushima1980.pdf},
  volume = {36},
  year = {1980},
}




@article {caliskan,
	author = {Caliskan, Aylin and Bryson, Joanna J. and Narayanan, Arvind},
	title = {<a href="https://www.cs.bath.ac.uk/~jjb/ftp/CaliskanEtAl-authors-full.pdf">Semantics derived automatically from language corpora contain human-like biases</a>},
	volume = {356},
	number = {6334},
	pages = {183--186},
	year = {2017},
	doi = {10.1126/science.aal4230},
	publisher = {American Association for the Advancement of Science},
	abstract = {AlphaGo has demonstrated that a machine can learn how to do things that people spend many years of concentrated study learning, and it can rapidly learn how to do them better than any human can. Caliskan et al. now show that machines can learn word associations from written texts and that these associations mirror those learned by humans, as measured by the Implicit Association Test (IAT) (see the Perspective by Greenwald). Why does this matter? Because the IAT has predictive value in uncovering the association between concepts, such as pleasantness and flowers or unpleasantness and insects. It can also tease out attitudes and beliefs{\textemdash}for example, associations between female names and family or male names and career. Such biases may not be expressed explicitly, yet they can prove influential in behavior.Science, this issue p. 183; see also p. 133Machine learning is a means to derive artificial intelligence by discovering patterns in existing data. Here, we show that applying machine learning to ordinary human language results in human-like semantic biases. We replicated a spectrum of known biases, as measured by the Implicit Association Test, using a widely used, purely statistical machine-learning model trained on a standard corpus of text from the World Wide Web. Our results indicate that text corpora contain recoverable and accurate imprints of our historic biases, whether morally neutral as toward insects or flowers, problematic as toward race or gender, or even simply veridical, reflecting the status quo distribution of gender with respect to careers or first names. Our methods hold promise for identifying and addressing sources of bias in culture, including technology.},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/356/6334/183},
	eprint = {https://science.sciencemag.org/content/356/6334/183.full.pdf},
	journal = {Science}
}

@inproceedings{arthurs,
  title = {<a href="https://educationaldatamining.org/files/conferences/EDM2020/papers/paper_18.pdf">Whose Truth is the "Ground Truth"? College Admissions Essays and Bias in Word Vector Evaluation Methods</a>},
  author = {Arthurs, Noah and Alvero, AJ},
  year = {2020},
  month = {07},
  pages = {},
  booktitle = {Educational Data Mining}
}


@article{rottentomatoes_kaggle,
  title = {<a href="https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews">Sentiment Analysis on Movie Reviews</a>},
  url = {https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews},
  journal = {Kaggle.com},
  year = {2015},
}

@article{NLPspec,
  author        = {Younes Bensouda Mourri and Łukasz Kaiser and Eddy Shyu and Andrew Ng},
  title         = {<a href="https://www.coursera.org/specializations/natural-language-processing">Natural Language Processing Specialization [MOOC]</a>},
  month         = {July},
  year          = {2020},
  journal       = {Coursera.com}
}

@article{NLPvect,
  author        = {Younes Bensouda Mourri and Łukasz Kaiser and Eddy Shyu and Andrew Ng},
  title         = {<a href="https://www.coursera.org/learn/classification-vector-spaces-in-nlp">Natural Language Processing with Classification and Vector Spaces [MOOC]</a>},
  month         = {July},
  year          = {2020},
  journal       = {Coursera.com}
}


@misc{lecun_gebru,
  author = {Kurenkov, Andrey},
  title     = {<a href="https://thegradient.pub/pulse-lessons/">Lessons from the PULSE Model and Discussion</a>},
  howpublished = {\url{https://thegradient.pub/pulse-lessons/}},
  month     = {June},
  year      = {2020},
  note      = {(Accessed on 07/11/2020)},
  journal   = {The Gradient}
}

@article{sargeant,
  author = {Richard Sargeant},
  title = {<a href="https://sargeant.me/2018/06/20/ai-ethics-send-money-guns-lawyers/">AI Ethics: send money, guns \& lawyers</a>},
  howpublished = {\url{https://sargeant.me/2018/06/20/ai-ethics-send-money-guns-lawyers/}},
  month = {June},
  year = {2018},
  journal = {sargeant.me},
  note = {(Accessed on 07/12/2020)},
}


@book{aftervirtue,
  title={After Virtue: A Study in Moral Theory},
  author={MacIntyre, Alasdair},
  isbn={9781623565251},
  publisher={University of Notre Dame Press},
  year={2007},
  edition = {3},
}


@misc{tf_codelabs,
author = {{Google Developers Codelabs}},
title = {<a href="https://codelabs.developers.google.com/codelabs/tensorflow-lab1-helloworld/#1">Learn TensorFlow 1: The "Hello World" of machine learning</a>},
howpublished = {\url{https://codelabs.developers.google.com/codelabs/tensorflow-lab1-helloworld/#1}},
month = {},
year = {Accessed on 07/14/2020},
note = {(Accessed on 07/14/2020), https://codelabs.developers.google.com/codelabs/tensorflow-lab1-helloworld/img/c72f871306134e45.png, https://codelabs.developers.google.com/codelabs/tensorflow-lab1-helloworld/img/d55ecc03b6c7b637.png}
}


@techreport{anatomyof,
  abstract = {A brief command and a response is the most common form of engagement with this consumer voice-enabled AI device. But in this fleeting moment of interaction, a vast matrix of capacities is invoked: interlaced chains of resource extraction, human labor and algorithmic processing across networks of mining, logistics, distribution, prediction and optimization. The scale of this system is almost beyond human imagining. How can we begin to see it, to grasp its immensity and complexity as a connected form? We start with an outline: an exploded view of a planetary system across three stages of birth, life and death, accompanied by an essay in 21 parts. Together, this becomes an anatomical map of a single AI system.},
  added-at = {2019-05-30T20:34:34.000+0200},
  address = {New York},
  author = {Crawford, Kate and Joler, Vladan},
  biburl = {https://www.bibsonomy.org/bibtex/212e2d340598de141a6fd15fe130a8a0a/meneteqel},
  institution = {AI Now Institute and Share Lab},
  interhash = {b606e30a03a7dd0ccccf387fa3f6b13c},
  intrahash = {12e2d340598de141a6fd15fe130a8a0a},
  keywords = {artificial_intelligence environmental_policy global_supply_chains platform_work sustainability},
  language = {eng},
  month = sep,
  timestamp = {2019-05-30T20:34:34.000+0200},
  title = {<a href="https://anatomyof.ai/">Anatomy of an AI System: The Amazon Echo As An Anatomical Map of Human Labor, Data and Planetary Resources</a>},
  type = {research report},
  url = {https://anatomyof.ai/},
  year = 2018
}



@misc{wiki_expert_system,
author = {},
title = {<a href="https://en.wikipedia.org/wiki/Expert_system">Expert system - Wikipedia</a>},
howpublished = {\url{https://en.wikipedia.org/wiki/Expert_system#:~:text=In%20artificial%20intelligence%2C%20an%20expert,than%20through%20conventional%20procedural%20code.}},
month = {},
year = {},
note = {(Accessed on 07/14/2020)}
}





@article{jesus_toast,
title = {<a href="http://www.sciencedirect.com/science/article/pii/S0010945214000288">Seeing Jesus in toast: Neural and behavioral correlates of face pareidolia</a>},
journal = "Cortex",
volume = "53",
pages = "60 - 77",
year = "2014",
issn = "0010-9452",
doi = "https://doi.org/10.1016/j.cortex.2014.01.013",
url = "http://www.sciencedirect.com/science/article/pii/S0010945214000288",
author = "Jiangang Liu and Jun Li and Lu Feng and Ling Li and Jie Tian and Kang Lee",
keywords = "Face processing, fMRI, Fusiform face area, Top-down processing, Face pareidolia",
abstract = "Face pareidolia is the illusory perception of non-existent faces. The present study, for the first time, contrasted behavioral and neural responses of face pareidolia with those of letter pareidolia to explore face-specific behavioral and neural responses during illusory face processing. Participants were shown pure-noise images but were led to believe that 50% of them contained either faces or letters; they reported seeing faces or letters illusorily 34% and 38% of the time, respectively. The right fusiform face area (rFFA) showed a specific response when participants “saw” faces as opposed to letters in the pure-noise images. Behavioral responses during face pareidolia produced a classification image (CI) that resembled a face, whereas those during letter pareidolia produced a CI that was letter-like. Further, the extent to which such behavioral CIs resembled faces was directly related to the level of face-specific activations in the rFFA. This finding suggests that the rFFA plays a specific role not only in processing of real faces but also in illusory face perception, perhaps serving to facilitate the interaction between bottom-up information from the primary visual cortex and top-down signals from the prefrontal cortex (PFC). Whole brain analyses revealed a network specialized in face pareidolia, including both the frontal and occipitotemporal regions. Our findings suggest that human face processing has a strong top-down component whereby sensory input with even the slightest suggestion of a face can result in the interpretation of a face."
}




@conference{jamellewd,
author = {Jamelle Watson-Daniels},
title = {<a href="https://slideslive.com/38930952/beyond-fairness-and-ethics-towards-agency-and-shifting-power">Beyond Fairness and Ethics: Towards Agency and Shifting Power</a>},
howpublished = {\url{https://slideslive.com/38930952/beyond-fairness-and-ethics-towards-agency-and-shifting-power}},
conference = {Participatory Approaches to Machine Learning},
booktile = {ICML 2020 Workshop},
month = {July},
year = {2020},
note = {(Accessed on 07/17/2020)},
url = {https://participatoryml.github.io/},
note={"Black folks need to be involved in data collection"}
}
